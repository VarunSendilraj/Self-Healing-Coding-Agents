#!/usr/bin/env python
"""
Test script to verify that LLM-based test case generation is working in enhanced_harness_integration.py
"""

import os
import sys
import tempfile
import json

# Add the src directory to the Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.join(current_dir, "src")
if src_dir not in sys.path:
    sys.path.insert(0, src_dir)

def patch_code_analyzer():
    """Patch the CodeAnalyzer class to use the correct runner path."""
    from code_analyzer import CodeAnalyzer
    
    # Store the original __init__ method
    original_init = CodeAnalyzer.__init__
    
    # Define a new __init__ method that uses the correct runner path
    def patched_init(self, runner_path=None):
        if runner_path is None:
            runner_path = os.path.join(current_dir, "code_runner.py")
        original_init(self, runner_path)
    
    # Apply the patch
    CodeAnalyzer.__init__ = patched_init

def create_test_task():
    """Create a test task for N-Queens to verify LLM test case generation."""
    task = {
        "id": "llm_test_generation_nqueens",
        "description": "The n-queens puzzle is the problem of placing n queens on an n√ón chessboard such that no two queens attack each other. Given an integer n, return the number of distinct solutions to the n-queens puzzle.",
        "initial_executor_prompt": "Implement a function called `totalNQueens` that takes an integer n and returns the total number of distinct solutions to the n-queens puzzle."
    }
    return task

def main():
    """Main test function."""
    try:
        # Apply the patch for CodeAnalyzer
        patch_code_analyzer()
        
        # Import the enhanced harness integration module
        from self_healing_agents.evaluation.enhanced_harness_integration import main as run_enhanced_harness
        
        # Create test tasks
        test_task = create_test_task()
        
        # Create a temporary file with the test task
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump([test_task], f, indent=2)
            temp_file = f.name
        
        print(f"Created test task file: {temp_file}")
        print(f"Test task: {test_task}")
        
        try:
            # Run the enhanced harness with our test task
            print("\n" + "="*50)
            print("RUNNING ENHANCED HARNESS WITH LLM TEST GENERATION")
            print("="*50)
            
            # Override sys.argv to pass the test file
            original_argv = sys.argv
            sys.argv = ['enhanced_harness_integration.py', temp_file]
            
            # Run the enhanced harness
            run_enhanced_harness()
            
        finally:
            # Restore original sys.argv
            sys.argv = original_argv
            
            # Clean up the temporary file
            if os.path.exists(temp_file):
                os.unlink(temp_file)
                print(f"Cleaned up temporary file: {temp_file}")
        
        print("\n" + "="*50)
        print("TEST COMPLETED SUCCESSFULLY")
        print("="*50)
        print("Check the evaluation_harness.log file to see:")
        print("1. Test cases generated by LLM")
        print("2. Test case execution results with stdout/stderr")
        print("3. Overall success/failure status")
        
    except Exception as e:
        print(f"Error in test: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 